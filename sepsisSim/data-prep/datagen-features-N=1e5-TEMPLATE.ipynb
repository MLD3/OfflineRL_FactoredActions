{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSIMSAMPS = 100_000    # Samples to draw from the simulator\n",
    "epsilon = ???          # epsilon-greedy behavior policy\n",
    "runs = list(range(10)) # Repeat for 10 replications\n",
    "\n",
    "output_dir = '../datagen/{}-100k/'.format(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['FreeSans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.753547Z",
     "start_time": "2019-04-19T16:43:04.068986Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cf.counterfactual as cf\n",
    "import cf.utils as utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools as it\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse\n",
    "\n",
    "# Sepsis Simulator code\n",
    "from sepsisSimDiabetes.State import State\n",
    "from sepsisSimDiabetes.Action import Action\n",
    "from sepsisSimDiabetes.DataGenerator import DataGenerator\n",
    "import sepsisSimDiabetes.MDP as simulator \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.787255Z",
     "start_time": "2019-04-19T16:43:04.770642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Max length of each trajectory\n",
    "NSTEPS = 20\n",
    "\n",
    "# Probability of diabetic state being set to 1\n",
    "PROB_DIAB = 0.2\n",
    "\n",
    "# Number of actions from properties of the simulator\n",
    "n_actions = Action.NUM_ACTIONS_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epsilon-greedy policy\n",
    "optPol = joblib.load('../data/Ï€_star.joblib')\n",
    "randomPol = np.ones_like(optPol) / n_actions\n",
    "behaviorPol = epsilon * randomPol + (1 - epsilon) * optPol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:12:19.355539Z",
     "start_time": "2019-04-19T17:12:19.340377Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_to_np(this_list):\n",
    "    this_arr = np.array(this_list)[:, np.newaxis]\n",
    "    # Make this idempotent\n",
    "    this_arr = this_arr.squeeze()[:, np.newaxis]\n",
    "    return this_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of data with N episodes each\n",
    "for it in runs:\n",
    "    print('Iteration:', it, flush=True)\n",
    "    np.random.seed(it)\n",
    "    dgen = DataGenerator()\n",
    "    states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals = dgen.simulate(\n",
    "       NSIMSAMPS, NSTEPS, policy=behaviorPol[:-2], policy_idx_type='full', output_state_idx_type='full',\n",
    "       p_diabetes=PROB_DIAB, modified=False, use_tqdm=True) #True, tqdm_desc='Behaviour Policy Simulation')\n",
    "\n",
    "    obs_samps = utils.format_dgen_samps(\n",
    "       states, actions, rewards, diab, NSTEPS, NSIMSAMPS)\n",
    "\n",
    "    df_samp_list = []\n",
    "    infos = []\n",
    "    for i in range(NSIMSAMPS):\n",
    "        pt_id = i + it*NSIMSAMPS\n",
    "        df_i, (len_i, y_i) = utils.df_from_samps(obs_samps, i, get_outcome=True, is_full=True)\n",
    "        df_i['pt_id'] = pt_id\n",
    "        df_i['Diabetic'] = diab[i][:len_i+1]\n",
    "        df_i['State_idx'] = states[i][:len_i+1]\n",
    "        df_i['Obs_idx'] = df_i['State_idx'].apply(lambda s: State(state_idx=s, idx_type='full').get_state_idx('obs'))\n",
    "        df_i['Proj_idx'] = df_i['State_idx'].apply(lambda s: State(state_idx=s, idx_type='full').get_state_idx('proj_obs'))\n",
    "        df_i['Action'] = actions[i][:len_i+1]\n",
    "        df_i['Reward'] = 0\n",
    "        df_i.loc[len_i, 'Reward'] = y_i\n",
    "        df_i = df_i.set_index('pt_id').reset_index()\n",
    "        df_samp_list.append(df_i)\n",
    "        infos.append([pt_id, diab[i][0], y_i, len_i, len(df_i)])\n",
    "\n",
    "    df_samps = pd.concat(df_samp_list).astype(int)\n",
    "    df_features = pd.get_dummies(df_samps, columns=['Diabetic', 'Heart Rate', 'SysBP', 'Percent O2', 'Glucose', 'Treat: AbX', 'Treat: Vaso', 'Treat: Vent'])\n",
    "    df_samps_info = pd.DataFrame(infos, columns=['pt_id', 'Diabetic', 'Outcome', 'Steps', 'Length']).astype(int)\n",
    "    \n",
    "    assert df_samps.shape[1] == 15\n",
    "    assert df_features.shape[1] == 28\n",
    "    assert df_samps_info.shape[1] == 5\n",
    "    df_samps.to_csv('{}/{}-samples.csv'.format(output_dir, it), index=False)\n",
    "    df_features.to_csv('{}/{}-features.csv'.format(output_dir, it), index=False)\n",
    "    df_samps_info.to_csv('{}/{}-info.csv'.format(output_dir, it), index=False)\n",
    "    joblib.dump([states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals], '{}/{}-alldata.joblib'.format(output_dir, it))\n",
    "    joblib.dump(obs_samps, '{}/{}-obs_samps.joblib'.format(output_dir, it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1440), df_samps.groupby('pt_id').first()['State_idx'].value_counts().reindex(range(1440)))\n",
    "plt.xlabel('initial state index')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21-dimensional state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS, nA = 1442, 8\n",
    "d = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_action_feature(x_s, a):\n",
    "    x_sa = np.zeros((nA, d))\n",
    "    x_sa[a, :] = x_s\n",
    "    return x_sa.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features_single_trajectory(df_i):\n",
    "    # Initial timestep\n",
    "    s_init = df_i.iloc[0, 7:28].values\n",
    "    x_s_init = np.array(s_init)\n",
    "    xa_s_init_all = np.array([get_state_action_feature(x_s_init, a_) for a_ in range(nA)])\n",
    "\n",
    "    # Intermediate timestep\n",
    "    if len(df_i) > 1:\n",
    "        s = df_i.iloc[:-1, 7:28].values\n",
    "        a = df_i.iloc[:-1]['Action'].values\n",
    "        r = df_i.iloc[:-1]['Reward'].values\n",
    "        s_next = df_i.iloc[1:, 7:28].values\n",
    "\n",
    "        n = len(s)\n",
    "        x_s = np.array(s)\n",
    "        xa_sa = np.array([get_state_action_feature(x_s[j, :], a[j]) for j in range(n)])\n",
    "\n",
    "        x_s_next = np.array(s_next)\n",
    "        xa_s_next_all = np.vstack([\n",
    "            np.vstack([get_state_action_feature(x_s_next[j], a_) for a_ in range(nA)]) \n",
    "            for j in range(n)\n",
    "        ])\n",
    "    else:\n",
    "        x_s = np.array((0, d))\n",
    "        a = np.zeros((0), dtype=int)\n",
    "        xa_sa = np.array((0, d*nA))\n",
    "        r = np.zeros((0))\n",
    "        x_s_next = np.array((0, d))\n",
    "        xa_s_next_all = np.array((0, d*nA))\n",
    "\n",
    "    # Final timestep\n",
    "    s_last = df_i.iloc[-1, 7:28].values\n",
    "    a_last = df_i.iloc[-1]['Action']\n",
    "    r_last = df_i.iloc[-1]['Reward']\n",
    "    if r_last == -1 or r_last == 1:\n",
    "        # Reached death/disch states\n",
    "        # every action leads to reward\n",
    "        x_s_last = np.array(s_last)\n",
    "        xa_s_last_all = np.array([get_state_action_feature(x_s_last, a_) for a_ in range(nA)])\n",
    "        r_last_all = np.array(nA * [r_last])\n",
    "\n",
    "        xa_out = np.vstack([xa_sa, xa_s_last_all])\n",
    "        xa_next_out = np.vstack([xa_s_next_all, np.zeros((nA*nA, nA*d))])\n",
    "        r_out = np.concatenate([r, r_last_all])\n",
    "\n",
    "        a_out = np.concatenate([a, (list(range(nA)))])\n",
    "        x_out = np.vstack([x_s, *(nA*[x_s_last])])\n",
    "        x_next_out = np.vstack([x_s_next, np.zeros((nA, d))])\n",
    "    else: \n",
    "        # terminated early due to max length, so no next state information\n",
    "        xa_out = xa_sa\n",
    "        xa_next_out = xa_s_next_all\n",
    "        r_out = r\n",
    "\n",
    "        x_out = x_s\n",
    "        a_out = a\n",
    "        x_next_out = x_s_next\n",
    "    \n",
    "    return x_s_init, xa_s_init_all, x_out, a_out, xa_out, r_out, x_next_out, xa_next_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in runs:\n",
    "    df_features = pd.read_csv('{}/{}-features.csv'.format(output_dir, it))\n",
    "    out = [make_features_single_trajectory(df_i) for i, df_i in tqdm(df_features.groupby('pt_id'))]\n",
    "    X_init, Xa_init, X, A, Xa, R, X_next, Xa_next = zip(*out)\n",
    "    X_init = np.vstack(X_init)\n",
    "    Xa_init = np.vstack(Xa_init)\n",
    "    X = np.vstack(X)\n",
    "    Xa = np.vstack(Xa)\n",
    "    A = np.concatenate(A)\n",
    "    R = np.concatenate(R)\n",
    "    X_next = np.vstack(X_next)\n",
    "    Xa_next = np.vstack(Xa_next)\n",
    "    print(Xa_init.shape, Xa.shape, Xa_next.shape, R.shape)\n",
    "    print(X_init.shape, X.shape, A.shape, R.shape, X_next.shape)\n",
    "\n",
    "    # Store indices of beginning of each episode\n",
    "    lengths = [len(x_i) for x_i in list(zip(*out))[2]]\n",
    "    inds_init = np.cumsum([0] + lengths)\n",
    "\n",
    "    joblib.dump({\n",
    "        'X_init': X_init, 'X': X, 'A': A, 'R': R, 'X_next': X_next, \n",
    "        'Xa_init': Xa_init, 'Xa': Xa, 'Xa_next': Xa_next,\n",
    "        'lengths': lengths, 'inds_init': inds_init,\n",
    "    }, '{}/{}-21d-feature-matrices.joblib'.format(output_dir, it))\n",
    "\n",
    "    joblib.dump({\n",
    "        'X_init': scipy.sparse.csr_matrix(X_init), 'X': scipy.sparse.csr_matrix(X), 'A': A, 'R': R, 'X_next': scipy.sparse.csr_matrix(X_next), \n",
    "        'Xa_init': scipy.sparse.csr_matrix(Xa_init), 'Xa': scipy.sparse.csr_matrix(Xa), 'Xa_next': scipy.sparse.csr_matrix(Xa_next),\n",
    "        'lengths': lengths, 'inds_init': inds_init,\n",
    "    }, '{}/{}-21d-feature-matrices.sparse.joblib'.format(output_dir, it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_lightning",
   "language": "python",
   "name": "py39_lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
