{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:54.898294Z",
     "iopub.status.busy": "2021-11-23T04:04:54.897735Z",
     "iopub.status.idle": "2021-11-23T04:04:54.900015Z",
     "shell.execute_reply": "2021-11-23T04:04:54.900542Z"
    }
   },
   "outputs": [],
   "source": [
    "NSIMSAMPS = 100_000    # Samples to draw from the simulator\n",
    "epsilon = 8/7          # epsilon-greedy behavior policy\n",
    "runs = list(range(10)) # Repeat for 10 replications\n",
    "\n",
    "output_dir = '../datagen/suboptimal-100k/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['FreeSans']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.753547Z",
     "start_time": "2019-04-19T16:43:04.068986Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cf.counterfactual as cf\n",
    "import cf.utils as utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools as it\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse\n",
    "\n",
    "# Sepsis Simulator code\n",
    "from sepsisSimDiabetes.State import State\n",
    "from sepsisSimDiabetes.Action import Action\n",
    "from sepsisSimDiabetes.DataGenerator import DataGenerator\n",
    "import sepsisSimDiabetes.MDP as simulator \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pathlib\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.787255Z",
     "start_time": "2019-04-19T16:43:04.770642Z"
    }
   },
   "source": [
    "# Max length of each trajectory\n",
    "NSTEPS = 20\n",
    "\n",
    "# Probability of diabetic state being set to 1\n",
    "PROB_DIAB = 0.2\n",
    "\n",
    "# Number of actions from properties of the simulator\n",
    "n_actions = Action.NUM_ACTIONS_TOTAL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create epsilon-greedy policy\n",
    "optPol = joblib.load('../data/Ï€_star.joblib')\n",
    "randomPol = np.ones_like(optPol) / n_actions\n",
    "behaviorPol = epsilon * randomPol + (1 - epsilon) * optPol\n",
    "behaviorPol[behaviorPol < 1e-15] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T17:12:19.355539Z",
     "start_time": "2019-04-19T17:12:19.340377Z"
    }
   },
   "source": [
    "def conv_to_np(this_list):\n",
    "    this_arr = np.array(this_list)[:, np.newaxis]\n",
    "    # Make this idempotent\n",
    "    this_arr = this_arr.squeeze()[:, np.newaxis]\n",
    "    return this_arr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate batches of data with N episodes each\n",
    "for it in runs:\n",
    "    print('Iteration:', it, flush=True)\n",
    "    np.random.seed(it)\n",
    "    dgen = DataGenerator()\n",
    "    states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals = dgen.simulate(\n",
    "       NSIMSAMPS, NSTEPS, policy=behaviorPol[:-2], policy_idx_type='full', output_state_idx_type='full',\n",
    "       p_diabetes=PROB_DIAB, modified=False, use_tqdm=True) #True, tqdm_desc='Behaviour Policy Simulation')\n",
    "\n",
    "    obs_samps = utils.format_dgen_samps(\n",
    "       states, actions, rewards, diab, NSTEPS, NSIMSAMPS)\n",
    "\n",
    "    df_samp_list = []\n",
    "    infos = []\n",
    "    for i in range(NSIMSAMPS):\n",
    "        pt_id = i + it*NSIMSAMPS\n",
    "        df_i, (len_i, y_i) = utils.df_from_samps(obs_samps, i, get_outcome=True, is_full=True)\n",
    "        df_i['pt_id'] = pt_id\n",
    "        df_i['Diabetic'] = diab[i][:len_i+1]\n",
    "        df_i['State_idx'] = states[i][:len_i+1]\n",
    "        df_i['Obs_idx'] = df_i['State_idx'].apply(lambda s: State(state_idx=s, idx_type='full').get_state_idx('obs'))\n",
    "        df_i['Proj_idx'] = df_i['State_idx'].apply(lambda s: State(state_idx=s, idx_type='full').get_state_idx('proj_obs'))\n",
    "        df_i['Action'] = actions[i][:len_i+1]\n",
    "        df_i['Reward'] = 0\n",
    "        df_i.loc[len_i, 'Reward'] = y_i\n",
    "        df_i = df_i.set_index('pt_id').reset_index()\n",
    "        df_samp_list.append(df_i)\n",
    "        infos.append([pt_id, diab[i][0], y_i, len_i, len(df_i)])\n",
    "\n",
    "    df_samps = pd.concat(df_samp_list).astype(int)\n",
    "    df_features = pd.get_dummies(df_samps, columns=['Diabetic', 'Heart Rate', 'SysBP', 'Percent O2', 'Glucose', 'Treat: AbX', 'Treat: Vaso', 'Treat: Vent'])\n",
    "    df_samps_info = pd.DataFrame(infos, columns=['pt_id', 'Diabetic', 'Outcome', 'Steps', 'Length']).astype(int)\n",
    "    \n",
    "    assert df_samps.shape[1] == 15\n",
    "    assert df_features.shape[1] == 28\n",
    "    assert df_samps_info.shape[1] == 5\n",
    "    df_samps.to_csv('{}/{}-samples.csv'.format(output_dir, it), index=False)\n",
    "    df_features.to_csv('{}/{}-features.csv'.format(output_dir, it), index=False)\n",
    "    df_samps_info.to_csv('{}/{}-info.csv'.format(output_dir, it), index=False)\n",
    "    joblib.dump([states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals], '{}/{}-alldata.joblib'.format(output_dir, it))\n",
    "    joblib.dump(obs_samps, '{}/{}-obs_samps.joblib'.format(output_dir, it))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.bar(range(1440), df_samps.groupby('pt_id').first()['State_idx'].value_counts().reindex(range(1440)))\n",
    "plt.xlabel('initial state index')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:54.904898Z",
     "iopub.status.busy": "2021-11-23T04:04:54.904363Z",
     "iopub.status.idle": "2021-11-23T04:04:58.084695Z",
     "shell.execute_reply": "2021-11-23T04:04:58.085210Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.088788Z",
     "iopub.status.busy": "2021-11-23T04:04:58.088281Z",
     "iopub.status.idle": "2021-11-23T04:04:58.559823Z",
     "shell.execute_reply": "2021-11-23T04:04:58.560332Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.563612Z",
     "iopub.status.busy": "2021-11-23T04:04:58.563107Z",
     "iopub.status.idle": "2021-11-23T04:04:58.565277Z",
     "shell.execute_reply": "2021-11-23T04:04:58.564754Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21-dimensional state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.568370Z",
     "iopub.status.busy": "2021-11-23T04:04:58.567875Z",
     "iopub.status.idle": "2021-11-23T04:04:58.569455Z",
     "shell.execute_reply": "2021-11-23T04:04:58.569942Z"
    }
   },
   "outputs": [],
   "source": [
    "nS, nA = 1442, 8\n",
    "d = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.573407Z",
     "iopub.status.busy": "2021-11-23T04:04:58.572912Z",
     "iopub.status.idle": "2021-11-23T04:04:58.574493Z",
     "shell.execute_reply": "2021-11-23T04:04:58.574978Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_state_action_feature(x_s, a):\n",
    "    x_sa = np.zeros((nA, d))\n",
    "    x_sa[a, :] = x_s\n",
    "    return x_sa.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.585917Z",
     "iopub.status.busy": "2021-11-23T04:04:58.585407Z",
     "iopub.status.idle": "2021-11-23T04:04:58.587064Z",
     "shell.execute_reply": "2021-11-23T04:04:58.587557Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_features_single_trajectory(df_i):\n",
    "    # Initial timestep\n",
    "    s_init = df_i.iloc[0, 7:28].values\n",
    "    x_s_init = np.array(s_init)\n",
    "    xa_s_init_all = np.array([get_state_action_feature(x_s_init, a_) for a_ in range(nA)])\n",
    "\n",
    "    # Intermediate timestep\n",
    "    if len(df_i) > 1:\n",
    "        s = df_i.iloc[:-1, 7:28].values\n",
    "        a = df_i.iloc[:-1]['Action'].values\n",
    "        r = df_i.iloc[:-1]['Reward'].values\n",
    "        s_next = df_i.iloc[1:, 7:28].values\n",
    "\n",
    "        n = len(s)\n",
    "        x_s = np.array(s)\n",
    "        xa_sa = np.array([get_state_action_feature(x_s[j, :], a[j]) for j in range(n)])\n",
    "\n",
    "        x_s_next = np.array(s_next)\n",
    "        xa_s_next_all = np.vstack([\n",
    "            np.vstack([get_state_action_feature(x_s_next[j], a_) for a_ in range(nA)]) \n",
    "            for j in range(n)\n",
    "        ])\n",
    "    else:\n",
    "        x_s = np.array((0, d))\n",
    "        a = np.zeros((0), dtype=int)\n",
    "        xa_sa = np.array((0, d*nA))\n",
    "        r = np.zeros((0))\n",
    "        x_s_next = np.array((0, d))\n",
    "        xa_s_next_all = np.array((0, d*nA))\n",
    "\n",
    "    # Final timestep\n",
    "    s_last = df_i.iloc[-1, 7:28].values\n",
    "    a_last = df_i.iloc[-1]['Action']\n",
    "    r_last = df_i.iloc[-1]['Reward']\n",
    "    if r_last == -1 or r_last == 1:\n",
    "        # Reached death/disch states\n",
    "        # every action leads to reward\n",
    "        x_s_last = np.array(s_last)\n",
    "        xa_s_last_all = np.array([get_state_action_feature(x_s_last, a_) for a_ in range(nA)])\n",
    "        r_last_all = np.array(nA * [r_last])\n",
    "\n",
    "        xa_out = np.vstack([xa_sa, xa_s_last_all])\n",
    "        xa_next_out = np.vstack([xa_s_next_all, np.zeros((nA*nA, nA*d))])\n",
    "        r_out = np.concatenate([r, r_last_all])\n",
    "\n",
    "        a_out = np.concatenate([a, (list(range(nA)))])\n",
    "        x_out = np.vstack([x_s, *(nA*[x_s_last])])\n",
    "        x_next_out = np.vstack([x_s_next, np.zeros((nA, d))])\n",
    "    else: \n",
    "        # terminated early due to max length, so no next state information\n",
    "        xa_out = xa_sa\n",
    "        xa_next_out = xa_s_next_all\n",
    "        r_out = r\n",
    "\n",
    "        x_out = x_s\n",
    "        a_out = a\n",
    "        x_next_out = x_s_next\n",
    "    \n",
    "    return x_s_init, xa_s_init_all, x_out, a_out, xa_out, r_out, x_next_out, xa_next_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T04:04:58.595486Z",
     "iopub.status.busy": "2021-11-23T04:04:58.594972Z",
     "iopub.status.idle": "2021-11-23T05:04:11.807434Z",
     "shell.execute_reply": "2021-11-23T05:04:11.802152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [03:01<00:00, 551.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1503553, 168) (12028424, 168) (1503553,)\n",
      "(100000, 21) (1503553, 21) (1503553,) (1503553,) (1503553, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [03:03<00:00, 546.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1505450, 168) (12043600, 168) (1505450,)\n",
      "(100000, 21) (1505450, 21) (1505450,) (1505450,) (1505450, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [02:57<00:00, 564.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1504864, 168) (12038912, 168) (1504864,)\n",
      "(100000, 21) (1504864, 21) (1504864,) (1504864,) (1504864, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [03:01<00:00, 551.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1505736, 168) (12045888, 168) (1505736,)\n",
      "(100000, 21) (1505736, 21) (1505736,) (1505736,) (1505736, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [03:00<00:00, 554.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1502535, 168) (12020280, 168) (1502535,)\n",
      "(100000, 21) (1502535, 21) (1502535,) (1502535,) (1502535, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [03:00<00:00, 553.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1503469, 168) (12027752, 168) (1503469,)\n",
      "(100000, 21) (1503469, 21) (1503469,) (1503469,) (1503469, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [02:59<00:00, 557.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1503154, 168) (12025232, 168) (1503154,)\n",
      "(100000, 21) (1503154, 21) (1503154,) (1503154,) (1503154, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [02:59<00:00, 556.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1503812, 168) (12030496, 168) (1503812,)\n",
      "(100000, 21) (1503812, 21) (1503812,) (1503812,) (1503812, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [02:59<00:00, 556.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1505702, 168) (12045616, 168) (1505702,)\n",
      "(100000, 21) (1505702, 21) (1505702,) (1505702,) (1505702, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [02:59<00:00, 556.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 168) (1501870, 168) (12014960, 168) (1501870,)\n",
      "(100000, 21) (1501870, 21) (1501870,) (1501870,) (1501870, 21)\n"
     ]
    }
   ],
   "source": [
    "for it in runs:\n",
    "    df_features = pd.read_csv('{}/{}-features.csv'.format(output_dir, it))\n",
    "    out = [make_features_single_trajectory(df_i) for i, df_i in tqdm(df_features.groupby('pt_id'))]\n",
    "    X_init, Xa_init, X, A, Xa, R, X_next, Xa_next = zip(*out)\n",
    "    X_init = np.vstack(X_init)\n",
    "    Xa_init = np.vstack(Xa_init)\n",
    "    X = np.vstack(X)\n",
    "    Xa = np.vstack(Xa)\n",
    "    A = np.concatenate(A)\n",
    "    R = np.concatenate(R)\n",
    "    X_next = np.vstack(X_next)\n",
    "    Xa_next = np.vstack(Xa_next)\n",
    "    print(Xa_init.shape, Xa.shape, Xa_next.shape, R.shape)\n",
    "    print(X_init.shape, X.shape, A.shape, R.shape, X_next.shape)\n",
    "\n",
    "    # Store indices of beginning of each episode\n",
    "    lengths = [len(x_i) for x_i in list(zip(*out))[2]]\n",
    "    inds_init = np.cumsum([0] + lengths)\n",
    "\n",
    "    joblib.dump({\n",
    "        'X_init': X_init, 'X': X, 'A': A, 'R': R, 'X_next': X_next, \n",
    "        'Xa_init': Xa_init, 'Xa': Xa, 'Xa_next': Xa_next,\n",
    "        'lengths': lengths, 'inds_init': inds_init,\n",
    "    }, '{}/{}-21d-feature-matrices.joblib'.format(output_dir, it))\n",
    "\n",
    "    joblib.dump({\n",
    "        'X_init': scipy.sparse.csr_matrix(X_init), 'X': scipy.sparse.csr_matrix(X), 'A': A, 'R': R, 'X_next': scipy.sparse.csr_matrix(X_next), \n",
    "        'Xa_init': scipy.sparse.csr_matrix(Xa_init), 'Xa': scipy.sparse.csr_matrix(Xa), 'Xa_next': scipy.sparse.csr_matrix(Xa_next),\n",
    "        'lengths': lengths, 'inds_init': inds_init,\n",
    "    }, '{}/{}-21d-feature-matrices.sparse.joblib'.format(output_dir, it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_lightning",
   "language": "python",
   "name": "py39_lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
