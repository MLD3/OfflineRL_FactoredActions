{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37820099-1651-4a6f-b859-565599e0c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a93ce6-d268-4f18-93c8-b0d9ae961002",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, va, te = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2895b8-7d1c-40d1-a85d-3fc8c1bec584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5000, -0.5000, -0.5000, -0.9758, -0.1789],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1789],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1789],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1458],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1375],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1375],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.9758, -0.1375],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ 0.7015, -0.7459, -0.7916, -0.3180, -0.0623,  0.5057,  0.7685, -0.4977,\n",
       "          -0.6755, -0.9433,  0.0645, -0.5053, -1.5709, -0.2812, -0.4705, -0.4922,\n",
       "          -0.6544, -0.6412, -0.2458,  1.5081, -0.7603, -0.3971,  1.0390, -1.5567,\n",
       "          -0.5769, -0.5619,  0.2050, -0.0969, -0.4849,  0.3393,  0.1503, -0.4947,\n",
       "          -0.2230],\n",
       "         [ 0.7015, -1.1189, -0.8351, -0.4553, -0.0893,  0.4045,  0.7093, -0.2805,\n",
       "          -0.5862,  1.1049,  1.0325, -1.1283,  0.1436, -1.0399, -0.4517,  0.2808,\n",
       "          -0.8254, -0.3581,  0.3979,  1.5081, -0.7603, -0.3971,  1.0390,  0.6608,\n",
       "          -0.5769, -0.6208,  0.5262, -1.0152, -0.6710, -0.1860, -0.1872,  1.6903,\n",
       "          -0.9656],\n",
       "         [ 0.7015, -1.0073, -0.4812, -0.1905, -0.0136, -0.0079,  0.7093, -0.2805,\n",
       "          -0.4969,  1.1049,  1.0325, -1.1283,  0.1436, -1.0399, -0.4329,  0.2808,\n",
       "          -0.8254, -0.3581,  0.3979,  1.5081, -0.7603, -0.3971,  1.0390,  0.6608,\n",
       "          -0.5769, -0.6208,  0.3372, -1.0152, -0.6710, -0.1860, -0.1872,  1.6903,\n",
       "          -0.9656],\n",
       "         [ 0.7015, -0.5409, -0.1653,  0.0380,  0.1081, -0.2785,  0.6658,  0.2625,\n",
       "          -0.4969,  1.1049,  1.0325, -0.8713,  0.1436, -1.0399, -0.4329,  0.2808,\n",
       "          -0.8254,  1.5750, -0.2312,  1.5081, -0.7603, -0.3971,  1.0390,  0.6608,\n",
       "           0.4380, -0.7270,  0.1233, -1.0152, -0.6710, -0.1860, -0.1872,  1.6903,\n",
       "          -0.2230],\n",
       "         [ 0.7015, -0.6007, -0.3233, -0.0056,  0.3676,  0.8426,  0.1225, -0.2805,\n",
       "          -0.4969,  1.1049,  1.0325, -0.4663,  0.1436, -1.0399, -0.4329,  0.2808,\n",
       "          -0.8254,  2.9463, -0.1434, -0.2563,  2.0116,  0.3323, -0.0669,  0.0560,\n",
       "          -0.1419,  1.4353,  0.1233, -1.0152, -0.6710, -0.1860, -0.1872,  1.6903,\n",
       "          -0.2230],\n",
       "         [ 0.7015, -0.4811, -0.4812, -0.2558,  0.2216,  1.4997, -0.3876, -0.9321,\n",
       "          -0.4969,  1.1049,  1.0325,  0.4683,  0.1436, -1.0399, -0.4329,  0.2808,\n",
       "          -0.8254,  0.9248, -0.3512,  0.2945,  1.2387,  0.0300,  0.3478, -0.7504,\n",
       "          -0.4319,  1.7249, -0.3083, -1.0152, -0.6710, -0.1860, -0.1872,  1.6903,\n",
       "          -0.4512],\n",
       "         [ 0.7015,  0.1646,  0.8419,  0.4297,  0.2379, -1.2835, -0.1438, -0.9321,\n",
       "          -1.0328,  0.0808, -0.0968, -0.8168,  1.0009, -1.2928, -0.4329, -0.1592,\n",
       "          -0.6544, -0.6456, -0.5238,  0.8079, -1.1692,  1.5742, -0.1130,  0.6608,\n",
       "          -0.3594, -0.8266,  1.1102, -1.0152, -0.8820, -0.2917, -0.1872,  1.5036,\n",
       "          -0.6976],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000]]),\n",
       " tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9426b07f-1408-47be-8f0c-c8e236652d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f31573f-3c58-4a32-ab55-6d47c323b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AIS_LSTM\n",
    "from data import MIMIC3SepsisDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0d50ae-4711-4606-8c99-b511b73212ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099fb5a9-9b65-42e1-b2ad-51ff22caad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MIMIC3SepsisDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca03858b-b6bd-41e3-97ec-b58cc350c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AIS_LSTM(\n",
    "    dm.observation_dim,\n",
    "    dm.context_dim,\n",
    "    dm.num_actions, \n",
    "    latent_dim=32,\n",
    "    lr=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7f0bd9-682f-4671-9f21-53acc1667c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "logger = TestTubeLogger(\"logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15d713a-5014-4462-93b4-71e81d0a4816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=0,\n",
    "    max_epochs=100, \n",
    "    stochastic_weight_avg=True,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=False),\n",
    "        pl.callbacks.ModelCheckpoint(monitor=\"train_loss\"),\n",
    "        pl.callbacks.ModelCheckpoint(monitor=\"val_loss\"),\n",
    "        pl.callbacks.ModelCheckpoint(monitor=\"val_mse\"),\n",
    "        pl.callbacks.ProgressBar(20),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2ebc9a-ebbf-4f4a-a46a-1c3b309f9bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | gen  | Sequential | 45.4 K\n",
      "1 | pred | Sequential | 28.2 K\n",
      "------------------------------------\n",
      "73.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "73.6 K    Total params\n",
      "0.295     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tangsp/.conda/envs/py39_lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "/home/tangsp/.conda/envs/py39_lightning/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  93%|█████████▎| 120/129 [00:03<00:00, 32.67it/s, loss=601, v_num=5, train_loss=568.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 129/129 [00:04<00:00, 29.99it/s, loss=598, v_num=5, train_loss=552.0, val_loss=577.0, val_mse=1.020]\n",
      "Epoch 1:  93%|█████████▎| 120/129 [00:03<00:00, 32.93it/s, loss=570, v_num=5, train_loss=584.0, val_loss=577.0, val_mse=1.020] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 129/129 [00:04<00:00, 30.25it/s, loss=574, v_num=5, train_loss=549.0, val_loss=559.0, val_mse=0.934]\n",
      "Epoch 2:  93%|█████████▎| 120/129 [00:03<00:00, 34.05it/s, loss=562, v_num=5, train_loss=543.0, val_loss=559.0, val_mse=0.934] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 129/129 [00:04<00:00, 31.14it/s, loss=557, v_num=5, train_loss=503.0, val_loss=547.0, val_mse=0.874]\n",
      "Epoch 3:  93%|█████████▎| 120/129 [00:03<00:00, 35.03it/s, loss=532, v_num=5, train_loss=518.0, val_loss=547.0, val_mse=0.874] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 129/129 [00:04<00:00, 32.05it/s, loss=532, v_num=5, train_loss=528.0, val_loss=534.0, val_mse=0.808]\n",
      "Epoch 4:  93%|█████████▎| 120/129 [00:03<00:00, 34.47it/s, loss=520, v_num=5, train_loss=536.0, val_loss=534.0, val_mse=0.808] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 129/129 [00:04<00:00, 31.24it/s, loss=518, v_num=5, train_loss=486.0, val_loss=522.0, val_mse=0.751]\n",
      "Epoch 5:  93%|█████████▎| 120/129 [00:03<00:00, 35.01it/s, loss=526, v_num=5, train_loss=522.0, val_loss=522.0, val_mse=0.751] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 129/129 [00:04<00:00, 31.64it/s, loss=522, v_num=5, train_loss=510.0, val_loss=513.0, val_mse=0.707]\n",
      "Epoch 6:  93%|█████████▎| 120/129 [00:03<00:00, 34.28it/s, loss=500, v_num=5, train_loss=498.0, val_loss=513.0, val_mse=0.707] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 129/129 [00:04<00:00, 31.19it/s, loss=503, v_num=5, train_loss=529.0, val_loss=506.0, val_mse=0.669]\n",
      "Epoch 7:  93%|█████████▎| 120/129 [00:03<00:00, 33.71it/s, loss=501, v_num=5, train_loss=488.0, val_loss=506.0, val_mse=0.669] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 129/129 [00:04<00:00, 30.77it/s, loss=529, v_num=5, train_loss=1.16e+3, val_loss=499.0, val_mse=0.634]\n",
      "Epoch 8:  93%|█████████▎| 120/129 [00:03<00:00, 33.59it/s, loss=504, v_num=5, train_loss=475.0, val_loss=499.0, val_mse=0.634]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 129/129 [00:04<00:00, 30.55it/s, loss=490, v_num=5, train_loss=493.0, val_loss=493.0, val_mse=0.608]\n",
      "Epoch 9:  93%|█████████▎| 120/129 [00:03<00:00, 34.13it/s, loss=487, v_num=5, train_loss=511.0, val_loss=493.0, val_mse=0.608] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 129/129 [00:04<00:00, 30.98it/s, loss=487, v_num=5, train_loss=450.0, val_loss=489.0, val_mse=0.588]\n",
      "Epoch 10:  93%|█████████▎| 120/129 [00:03<00:00, 34.11it/s, loss=497, v_num=5, train_loss=461.0, val_loss=489.0, val_mse=0.588]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 129/129 [00:04<00:00, 31.37it/s, loss=497, v_num=5, train_loss=459.0, val_loss=486.0, val_mse=0.571]\n",
      "Epoch 11:  93%|█████████▎| 120/129 [00:03<00:00, 33.41it/s, loss=509, v_num=5, train_loss=476.0, val_loss=486.0, val_mse=0.571] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 129/129 [00:04<00:00, 30.73it/s, loss=500, v_num=5, train_loss=519.0, val_loss=483.0, val_mse=0.557]\n",
      "Epoch 12:  93%|█████████▎| 120/129 [00:03<00:00, 33.26it/s, loss=480, v_num=5, train_loss=485.0, val_loss=483.0, val_mse=0.557] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 129/129 [00:04<00:00, 30.51it/s, loss=490, v_num=5, train_loss=508.0, val_loss=481.0, val_mse=0.544]\n",
      "Epoch 13:  93%|█████████▎| 120/129 [00:03<00:00, 33.78it/s, loss=508, v_num=5, train_loss=479.0, val_loss=481.0, val_mse=0.544] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 129/129 [00:04<00:00, 31.10it/s, loss=510, v_num=5, train_loss=474.0, val_loss=478.0, val_mse=0.533]\n",
      "Epoch 14:  93%|█████████▎| 120/129 [00:03<00:00, 34.42it/s, loss=474, v_num=5, train_loss=491.0, val_loss=478.0, val_mse=0.533] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 129/129 [00:04<00:00, 31.41it/s, loss=477, v_num=5, train_loss=443.0, val_loss=476.0, val_mse=0.521]\n",
      "Epoch 15:  93%|█████████▎| 120/129 [00:03<00:00, 34.08it/s, loss=475, v_num=5, train_loss=476.0, val_loss=476.0, val_mse=0.521] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 129/129 [00:04<00:00, 31.10it/s, loss=499, v_num=5, train_loss=477.0, val_loss=474.0, val_mse=0.511]\n",
      "Epoch 16:  93%|█████████▎| 120/129 [00:03<00:00, 33.71it/s, loss=499, v_num=5, train_loss=466.0, val_loss=474.0, val_mse=0.511] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 129/129 [00:04<00:00, 30.96it/s, loss=485, v_num=5, train_loss=456.0, val_loss=472.0, val_mse=0.502]\n",
      "Epoch 17:  93%|█████████▎| 120/129 [00:03<00:00, 34.63it/s, loss=497, v_num=5, train_loss=473.0, val_loss=472.0, val_mse=0.502] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 129/129 [00:04<00:00, 31.50it/s, loss=499, v_num=5, train_loss=472.0, val_loss=470.0, val_mse=0.495]\n",
      "Epoch 18:  93%|█████████▎| 120/129 [00:03<00:00, 33.78it/s, loss=482, v_num=5, train_loss=484.0, val_loss=470.0, val_mse=0.495] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 129/129 [00:04<00:00, 30.87it/s, loss=486, v_num=5, train_loss=491.0, val_loss=469.0, val_mse=0.488]\n",
      "Epoch 19:  93%|█████████▎| 120/129 [00:03<00:00, 33.66it/s, loss=495, v_num=5, train_loss=703.0, val_loss=469.0, val_mse=0.488] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 129/129 [00:04<00:00, 30.40it/s, loss=493, v_num=5, train_loss=469.0, val_loss=468.0, val_mse=0.483]\n",
      "Epoch 20:  93%|█████████▎| 120/129 [00:03<00:00, 34.32it/s, loss=487, v_num=5, train_loss=440.0, val_loss=468.0, val_mse=0.483] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 129/129 [00:04<00:00, 31.63it/s, loss=489, v_num=5, train_loss=521.0, val_loss=467.0, val_mse=0.477]\n",
      "Epoch 21:  93%|█████████▎| 120/129 [00:03<00:00, 34.19it/s, loss=479, v_num=5, train_loss=445.0, val_loss=467.0, val_mse=0.477] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 129/129 [00:04<00:00, 30.93it/s, loss=467, v_num=5, train_loss=476.0, val_loss=466.0, val_mse=0.473]\n",
      "Epoch 22:  93%|█████████▎| 120/129 [00:03<00:00, 34.47it/s, loss=468, v_num=5, train_loss=479.0, val_loss=466.0, val_mse=0.473] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 129/129 [00:04<00:00, 31.14it/s, loss=470, v_num=5, train_loss=465.0, val_loss=465.0, val_mse=0.469]\n",
      "Epoch 23:  93%|█████████▎| 120/129 [00:03<00:00, 33.07it/s, loss=475, v_num=5, train_loss=481.0, val_loss=465.0, val_mse=0.469] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 129/129 [00:04<00:00, 30.35it/s, loss=475, v_num=5, train_loss=453.0, val_loss=465.0, val_mse=0.465]\n",
      "Epoch 24:  93%|█████████▎| 120/129 [00:03<00:00, 33.81it/s, loss=459, v_num=5, train_loss=446.0, val_loss=465.0, val_mse=0.465] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 129/129 [00:04<00:00, 30.82it/s, loss=497, v_num=5, train_loss=1.18e+3, val_loss=464.0, val_mse=0.462]\n",
      "Epoch 25:  93%|█████████▎| 120/129 [00:03<00:00, 33.70it/s, loss=478, v_num=5, train_loss=479.0, val_loss=464.0, val_mse=0.462]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 129/129 [00:04<00:00, 30.72it/s, loss=474, v_num=5, train_loss=450.0, val_loss=463.0, val_mse=0.459]\n",
      "Epoch 26:  93%|█████████▎| 120/129 [00:03<00:00, 34.09it/s, loss=479, v_num=5, train_loss=455.0, val_loss=463.0, val_mse=0.459] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 129/129 [00:04<00:00, 31.27it/s, loss=484, v_num=5, train_loss=499.0, val_loss=463.0, val_mse=0.455]\n",
      "Epoch 27:  93%|█████████▎| 120/129 [00:03<00:00, 33.11it/s, loss=462, v_num=5, train_loss=490.0, val_loss=463.0, val_mse=0.455] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 129/129 [00:04<00:00, 30.14it/s, loss=477, v_num=5, train_loss=442.0, val_loss=462.0, val_mse=0.453]\n",
      "Epoch 28:  93%|█████████▎| 120/129 [00:03<00:00, 34.21it/s, loss=459, v_num=5, train_loss=455.0, val_loss=462.0, val_mse=0.453] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 129/129 [00:04<00:00, 31.22it/s, loss=458, v_num=5, train_loss=443.0, val_loss=462.0, val_mse=0.451]\n",
      "Epoch 29:  93%|█████████▎| 120/129 [00:03<00:00, 33.87it/s, loss=469, v_num=5, train_loss=469.0, val_loss=462.0, val_mse=0.451] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 129/129 [00:04<00:00, 31.17it/s, loss=471, v_num=5, train_loss=464.0, val_loss=461.0, val_mse=0.448]\n",
      "Epoch 30:  93%|█████████▎| 120/129 [00:03<00:00, 34.38it/s, loss=472, v_num=5, train_loss=477.0, val_loss=461.0, val_mse=0.448] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 129/129 [00:04<00:00, 31.56it/s, loss=462, v_num=5, train_loss=451.0, val_loss=461.0, val_mse=0.446]\n",
      "Epoch 31:  93%|█████████▎| 120/129 [00:03<00:00, 33.39it/s, loss=461, v_num=5, train_loss=450.0, val_loss=461.0, val_mse=0.446] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 129/129 [00:04<00:00, 30.75it/s, loss=459, v_num=5, train_loss=444.0, val_loss=460.0, val_mse=0.444]\n",
      "Epoch 32:  93%|█████████▎| 120/129 [00:03<00:00, 33.88it/s, loss=491, v_num=5, train_loss=485.0, val_loss=460.0, val_mse=0.444] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|██████████| 129/129 [00:04<00:00, 30.89it/s, loss=476, v_num=5, train_loss=466.0, val_loss=460.0, val_mse=0.442]\n",
      "Epoch 33:  93%|█████████▎| 120/129 [00:03<00:00, 34.02it/s, loss=462, v_num=5, train_loss=455.0, val_loss=460.0, val_mse=0.442] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 129/129 [00:04<00:00, 31.31it/s, loss=476, v_num=5, train_loss=464.0, val_loss=460.0, val_mse=0.440]\n",
      "Epoch 34:  93%|█████████▎| 120/129 [00:03<00:00, 34.45it/s, loss=478, v_num=5, train_loss=469.0, val_loss=460.0, val_mse=0.440] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 129/129 [00:04<00:00, 31.55it/s, loss=483, v_num=5, train_loss=462.0, val_loss=459.0, val_mse=0.438]\n",
      "Epoch 35:  93%|█████████▎| 120/129 [00:03<00:00, 34.00it/s, loss=463, v_num=5, train_loss=484.0, val_loss=459.0, val_mse=0.438] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 129/129 [00:04<00:00, 31.24it/s, loss=462, v_num=5, train_loss=499.0, val_loss=459.0, val_mse=0.437]\n",
      "Epoch 36:  93%|█████████▎| 120/129 [00:03<00:00, 33.88it/s, loss=462, v_num=5, train_loss=454.0, val_loss=459.0, val_mse=0.437] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|██████████| 129/129 [00:04<00:00, 31.02it/s, loss=478, v_num=5, train_loss=477.0, val_loss=458.0, val_mse=0.435]\n",
      "Epoch 37:  93%|█████████▎| 120/129 [00:03<00:00, 33.48it/s, loss=461, v_num=5, train_loss=476.0, val_loss=458.0, val_mse=0.435] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 129/129 [00:04<00:00, 30.76it/s, loss=460, v_num=5, train_loss=455.0, val_loss=458.0, val_mse=0.433]\n",
      "Epoch 38:  93%|█████████▎| 120/129 [00:03<00:00, 33.92it/s, loss=466, v_num=5, train_loss=460.0, val_loss=458.0, val_mse=0.433] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 129/129 [00:04<00:00, 31.16it/s, loss=473, v_num=5, train_loss=446.0, val_loss=458.0, val_mse=0.432]\n",
      "Epoch 39:  93%|█████████▎| 120/129 [00:03<00:00, 33.72it/s, loss=461, v_num=5, train_loss=469.0, val_loss=458.0, val_mse=0.432] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 129/129 [00:04<00:00, 30.70it/s, loss=457, v_num=5, train_loss=412.0, val_loss=458.0, val_mse=0.430]\n",
      "Epoch 40:  93%|█████████▎| 120/129 [00:03<00:00, 33.80it/s, loss=464, v_num=5, train_loss=461.0, val_loss=458.0, val_mse=0.430] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 129/129 [00:04<00:00, 30.92it/s, loss=459, v_num=5, train_loss=445.0, val_loss=457.0, val_mse=0.429]\n",
      "Epoch 41:  93%|█████████▎| 120/129 [00:03<00:00, 34.02it/s, loss=457, v_num=5, train_loss=445.0, val_loss=457.0, val_mse=0.429] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 129/129 [00:04<00:00, 31.25it/s, loss=460, v_num=5, train_loss=455.0, val_loss=457.0, val_mse=0.428]\n",
      "Epoch 42:  93%|█████████▎| 120/129 [00:03<00:00, 33.67it/s, loss=490, v_num=5, train_loss=435.0, val_loss=457.0, val_mse=0.428] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 129/129 [00:04<00:00, 30.83it/s, loss=491, v_num=5, train_loss=465.0, val_loss=457.0, val_mse=0.427]\n",
      "Epoch 43:  93%|█████████▎| 120/129 [00:03<00:00, 33.46it/s, loss=462, v_num=5, train_loss=474.0, val_loss=457.0, val_mse=0.427] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 129/129 [00:04<00:00, 30.73it/s, loss=460, v_num=5, train_loss=437.0, val_loss=457.0, val_mse=0.426]\n",
      "Epoch 44:  93%|█████████▎| 120/129 [00:03<00:00, 33.99it/s, loss=457, v_num=5, train_loss=458.0, val_loss=457.0, val_mse=0.426] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 129/129 [00:04<00:00, 31.01it/s, loss=456, v_num=5, train_loss=457.0, val_loss=457.0, val_mse=0.426]\n",
      "Epoch 45:  93%|█████████▎| 120/129 [00:03<00:00, 33.93it/s, loss=473, v_num=5, train_loss=465.0, val_loss=457.0, val_mse=0.426] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 129/129 [00:04<00:00, 31.18it/s, loss=472, v_num=5, train_loss=452.0, val_loss=456.0, val_mse=0.425]\n",
      "Epoch 46:  93%|█████████▎| 120/129 [00:03<00:00, 33.52it/s, loss=448, v_num=5, train_loss=426.0, val_loss=456.0, val_mse=0.425] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 129/129 [00:04<00:00, 30.51it/s, loss=462, v_num=5, train_loss=440.0, val_loss=456.0, val_mse=0.424]\n",
      "Epoch 47:  93%|█████████▎| 120/129 [00:03<00:00, 34.41it/s, loss=450, v_num=5, train_loss=428.0, val_loss=456.0, val_mse=0.424] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 129/129 [00:04<00:00, 31.57it/s, loss=454, v_num=5, train_loss=460.0, val_loss=456.0, val_mse=0.423]\n",
      "Epoch 48:  93%|█████████▎| 120/129 [00:03<00:00, 33.59it/s, loss=473, v_num=5, train_loss=480.0, val_loss=456.0, val_mse=0.423] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 129/129 [00:04<00:00, 30.60it/s, loss=459, v_num=5, train_loss=458.0, val_loss=456.0, val_mse=0.423]\n",
      "Epoch 49:  93%|█████████▎| 120/129 [00:03<00:00, 33.48it/s, loss=458, v_num=5, train_loss=463.0, val_loss=456.0, val_mse=0.423] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 129/129 [00:04<00:00, 30.68it/s, loss=458, v_num=5, train_loss=410.0, val_loss=456.0, val_mse=0.422]\n",
      "Epoch 50:  93%|█████████▎| 120/129 [00:03<00:00, 33.45it/s, loss=472, v_num=5, train_loss=446.0, val_loss=456.0, val_mse=0.422] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50: 100%|██████████| 129/129 [00:04<00:00, 30.82it/s, loss=466, v_num=5, train_loss=412.0, val_loss=456.0, val_mse=0.421]\n",
      "Epoch 51:  93%|█████████▎| 120/129 [00:03<00:00, 34.55it/s, loss=469, v_num=5, train_loss=436.0, val_loss=456.0, val_mse=0.421] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51: 100%|██████████| 129/129 [00:04<00:00, 31.51it/s, loss=471, v_num=5, train_loss=476.0, val_loss=456.0, val_mse=0.421]\n",
      "Epoch 52:  93%|█████████▎| 120/129 [00:03<00:00, 34.13it/s, loss=476, v_num=5, train_loss=477.0, val_loss=456.0, val_mse=0.421] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52: 100%|██████████| 129/129 [00:04<00:00, 31.24it/s, loss=458, v_num=5, train_loss=410.0, val_loss=455.0, val_mse=0.420]\n",
      "Epoch 53:  93%|█████████▎| 120/129 [00:03<00:00, 33.72it/s, loss=457, v_num=5, train_loss=437.0, val_loss=455.0, val_mse=0.420] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53: 100%|██████████| 129/129 [00:04<00:00, 30.93it/s, loss=458, v_num=5, train_loss=459.0, val_loss=455.0, val_mse=0.420]\n",
      "Epoch 54:  93%|█████████▎| 120/129 [00:03<00:00, 33.76it/s, loss=461, v_num=5, train_loss=464.0, val_loss=455.0, val_mse=0.420] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54: 100%|██████████| 129/129 [00:04<00:00, 30.90it/s, loss=459, v_num=5, train_loss=425.0, val_loss=455.0, val_mse=0.419]\n",
      "Epoch 55:  93%|█████████▎| 120/129 [00:03<00:00, 33.29it/s, loss=468, v_num=5, train_loss=476.0, val_loss=455.0, val_mse=0.419] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55: 100%|██████████| 129/129 [00:04<00:00, 30.71it/s, loss=483, v_num=5, train_loss=491.0, val_loss=455.0, val_mse=0.419]\n",
      "Epoch 56:  93%|█████████▎| 120/129 [00:03<00:00, 34.10it/s, loss=454, v_num=5, train_loss=468.0, val_loss=455.0, val_mse=0.419] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56: 100%|██████████| 129/129 [00:04<00:00, 31.27it/s, loss=458, v_num=5, train_loss=454.0, val_loss=455.0, val_mse=0.418]\n",
      "Epoch 57:  93%|█████████▎| 120/129 [00:03<00:00, 34.09it/s, loss=462, v_num=5, train_loss=463.0, val_loss=455.0, val_mse=0.418] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57: 100%|██████████| 129/129 [00:04<00:00, 31.26it/s, loss=484, v_num=5, train_loss=910.0, val_loss=455.0, val_mse=0.418]\n",
      "Epoch 58:  93%|█████████▎| 120/129 [00:03<00:00, 33.79it/s, loss=457, v_num=5, train_loss=444.0, val_loss=455.0, val_mse=0.418] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58: 100%|██████████| 129/129 [00:04<00:00, 31.12it/s, loss=454, v_num=5, train_loss=464.0, val_loss=455.0, val_mse=0.418]\n",
      "Epoch 59:  93%|█████████▎| 120/129 [00:03<00:00, 33.43it/s, loss=459, v_num=5, train_loss=462.0, val_loss=455.0, val_mse=0.418] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59: 100%|██████████| 129/129 [00:04<00:00, 30.70it/s, loss=462, v_num=5, train_loss=506.0, val_loss=455.0, val_mse=0.417]\n",
      "Epoch 60:  93%|█████████▎| 120/129 [00:03<00:00, 34.12it/s, loss=451, v_num=5, train_loss=463.0, val_loss=455.0, val_mse=0.417] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60: 100%|██████████| 129/129 [00:04<00:00, 30.80it/s, loss=451, v_num=5, train_loss=465.0, val_loss=455.0, val_mse=0.417]\n",
      "Epoch 61:  93%|█████████▎| 120/129 [00:03<00:00, 33.53it/s, loss=465, v_num=5, train_loss=678.0, val_loss=455.0, val_mse=0.417] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61: 100%|██████████| 129/129 [00:04<00:00, 30.80it/s, loss=466, v_num=5, train_loss=416.0, val_loss=455.0, val_mse=0.416]\n",
      "Epoch 62:  93%|█████████▎| 120/129 [00:03<00:00, 33.93it/s, loss=462, v_num=5, train_loss=470.0, val_loss=455.0, val_mse=0.416] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62: 100%|██████████| 129/129 [00:04<00:00, 31.15it/s, loss=467, v_num=5, train_loss=481.0, val_loss=455.0, val_mse=0.416]\n",
      "Epoch 63:  93%|█████████▎| 120/129 [00:03<00:00, 33.98it/s, loss=480, v_num=5, train_loss=459.0, val_loss=455.0, val_mse=0.416] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63: 100%|██████████| 129/129 [00:04<00:00, 31.29it/s, loss=479, v_num=5, train_loss=467.0, val_loss=455.0, val_mse=0.416]\n",
      "Epoch 64:  93%|█████████▎| 120/129 [00:03<00:00, 34.03it/s, loss=470, v_num=5, train_loss=443.0, val_loss=455.0, val_mse=0.416] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64: 100%|██████████| 129/129 [00:04<00:00, 30.79it/s, loss=460, v_num=5, train_loss=435.0, val_loss=454.0, val_mse=0.415]\n",
      "Epoch 65:  93%|█████████▎| 120/129 [00:03<00:00, 33.80it/s, loss=460, v_num=5, train_loss=459.0, val_loss=454.0, val_mse=0.415] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65: 100%|██████████| 129/129 [00:04<00:00, 31.02it/s, loss=456, v_num=5, train_loss=437.0, val_loss=454.0, val_mse=0.415]\n",
      "Epoch 66:  93%|█████████▎| 120/129 [00:03<00:00, 32.24it/s, loss=453, v_num=5, train_loss=448.0, val_loss=454.0, val_mse=0.415] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66: 100%|██████████| 129/129 [00:04<00:00, 29.77it/s, loss=455, v_num=5, train_loss=479.0, val_loss=454.0, val_mse=0.415]\n",
      "Epoch 67:  93%|█████████▎| 120/129 [00:03<00:00, 32.86it/s, loss=457, v_num=5, train_loss=474.0, val_loss=454.0, val_mse=0.415] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67: 100%|██████████| 129/129 [00:04<00:00, 30.10it/s, loss=453, v_num=5, train_loss=469.0, val_loss=454.0, val_mse=0.414]\n",
      "Epoch 68:  93%|█████████▎| 120/129 [00:03<00:00, 33.80it/s, loss=457, v_num=5, train_loss=472.0, val_loss=454.0, val_mse=0.414] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68: 100%|██████████| 129/129 [00:04<00:00, 31.13it/s, loss=456, v_num=5, train_loss=458.0, val_loss=454.0, val_mse=0.414]\n",
      "Epoch 69:  93%|█████████▎| 120/129 [00:03<00:00, 34.14it/s, loss=450, v_num=5, train_loss=446.0, val_loss=454.0, val_mse=0.414] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69: 100%|██████████| 129/129 [00:04<00:00, 31.17it/s, loss=454, v_num=5, train_loss=465.0, val_loss=454.0, val_mse=0.414]\n",
      "Epoch 70:  93%|█████████▎| 120/129 [00:03<00:00, 33.62it/s, loss=456, v_num=5, train_loss=451.0, val_loss=454.0, val_mse=0.414] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70: 100%|██████████| 129/129 [00:04<00:00, 30.28it/s, loss=454, v_num=5, train_loss=443.0, val_loss=454.0, val_mse=0.414]\n",
      "Epoch 71:  93%|█████████▎| 120/129 [00:03<00:00, 33.69it/s, loss=464, v_num=5, train_loss=456.0, val_loss=454.0, val_mse=0.414] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71: 100%|██████████| 129/129 [00:04<00:00, 30.83it/s, loss=451, v_num=5, train_loss=438.0, val_loss=454.0, val_mse=0.413]\n",
      "Epoch 72:  93%|█████████▎| 120/129 [00:03<00:00, 33.90it/s, loss=469, v_num=5, train_loss=445.0, val_loss=454.0, val_mse=0.413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72: 100%|██████████| 129/129 [00:04<00:00, 31.12it/s, loss=466, v_num=5, train_loss=447.0, val_loss=454.0, val_mse=0.413]\n",
      "Epoch 73:  93%|█████████▎| 120/129 [00:03<00:00, 33.23it/s, loss=463, v_num=5, train_loss=456.0, val_loss=454.0, val_mse=0.413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73: 100%|██████████| 129/129 [00:04<00:00, 30.42it/s, loss=464, v_num=5, train_loss=451.0, val_loss=454.0, val_mse=0.413]\n",
      "Epoch 74:  93%|█████████▎| 120/129 [00:03<00:00, 33.09it/s, loss=455, v_num=5, train_loss=463.0, val_loss=454.0, val_mse=0.413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74: 100%|██████████| 129/129 [00:04<00:00, 30.53it/s, loss=458, v_num=5, train_loss=459.0, val_loss=454.0, val_mse=0.413]\n",
      "Epoch 75:  93%|█████████▎| 120/129 [00:03<00:00, 32.04it/s, loss=451, v_num=5, train_loss=457.0, val_loss=454.0, val_mse=0.413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75: 100%|██████████| 129/129 [00:04<00:00, 29.68it/s, loss=455, v_num=5, train_loss=478.0, val_loss=454.0, val_mse=0.413]\n",
      "Epoch 76:  93%|█████████▎| 120/129 [00:03<00:00, 34.35it/s, loss=458, v_num=5, train_loss=419.0, val_loss=454.0, val_mse=0.413] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76: 100%|██████████| 129/129 [00:04<00:00, 31.64it/s, loss=451, v_num=5, train_loss=457.0, val_loss=454.0, val_mse=0.412]\n",
      "Epoch 77:  93%|█████████▎| 120/129 [00:03<00:00, 34.29it/s, loss=457, v_num=5, train_loss=439.0, val_loss=454.0, val_mse=0.412] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77: 100%|██████████| 129/129 [00:04<00:00, 31.57it/s, loss=457, v_num=5, train_loss=447.0, val_loss=454.0, val_mse=0.412]\n",
      "Epoch 78:  93%|█████████▎| 120/129 [00:03<00:00, 33.85it/s, loss=466, v_num=5, train_loss=465.0, val_loss=454.0, val_mse=0.412] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78: 100%|██████████| 129/129 [00:04<00:00, 30.93it/s, loss=450, v_num=5, train_loss=457.0, val_loss=454.0, val_mse=0.412]\n",
      "Epoch 79:  93%|█████████▎| 120/129 [00:03<00:00, 33.62it/s, loss=455, v_num=5, train_loss=454.0, val_loss=454.0, val_mse=0.412] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79: 100%|██████████| 129/129 [00:04<00:00, 30.87it/s, loss=457, v_num=5, train_loss=418.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 80:  93%|█████████▎| 120/129 [00:03<00:00, 33.95it/s, loss=470, v_num=5, train_loss=461.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80: 100%|██████████| 129/129 [00:04<00:00, 31.24it/s, loss=460, v_num=5, train_loss=498.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 81:  93%|█████████▎| 120/129 [00:03<00:00, 34.59it/s, loss=459, v_num=5, train_loss=450.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81: 100%|██████████| 129/129 [00:04<00:00, 31.63it/s, loss=468, v_num=5, train_loss=433.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 82:  93%|█████████▎| 120/129 [00:03<00:00, 32.07it/s, loss=466, v_num=5, train_loss=456.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82: 100%|██████████| 129/129 [00:04<00:00, 29.67it/s, loss=458, v_num=5, train_loss=481.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 83:  93%|█████████▎| 120/129 [00:03<00:00, 33.56it/s, loss=467, v_num=5, train_loss=440.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83: 100%|██████████| 129/129 [00:04<00:00, 30.97it/s, loss=467, v_num=5, train_loss=483.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 84:  93%|█████████▎| 120/129 [00:03<00:00, 34.10it/s, loss=450, v_num=5, train_loss=465.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84: 100%|██████████| 129/129 [00:04<00:00, 31.26it/s, loss=450, v_num=5, train_loss=435.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 85:  93%|█████████▎| 120/129 [00:03<00:00, 33.45it/s, loss=449, v_num=5, train_loss=438.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85: 100%|██████████| 129/129 [00:04<00:00, 30.72it/s, loss=453, v_num=5, train_loss=458.0, val_loss=453.0, val_mse=0.410]\n",
      "Epoch 86:  93%|█████████▎| 120/129 [00:03<00:00, 34.08it/s, loss=462, v_num=5, train_loss=464.0, val_loss=453.0, val_mse=0.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86: 100%|██████████| 129/129 [00:04<00:00, 31.16it/s, loss=460, v_num=5, train_loss=447.0, val_loss=454.0, val_mse=0.411]\n",
      "Epoch 87:  93%|█████████▎| 120/129 [00:03<00:00, 34.26it/s, loss=458, v_num=5, train_loss=458.0, val_loss=454.0, val_mse=0.411] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87: 100%|██████████| 129/129 [00:04<00:00, 31.42it/s, loss=455, v_num=5, train_loss=435.0, val_loss=453.0, val_mse=0.410]\n",
      "Epoch 88:  93%|█████████▎| 120/129 [00:03<00:00, 34.15it/s, loss=471, v_num=5, train_loss=471.0, val_loss=453.0, val_mse=0.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88: 100%|██████████| 129/129 [00:04<00:00, 31.25it/s, loss=471, v_num=5, train_loss=473.0, val_loss=453.0, val_mse=0.410]\n",
      "Epoch 89:  93%|█████████▎| 120/129 [00:03<00:00, 34.13it/s, loss=453, v_num=5, train_loss=458.0, val_loss=453.0, val_mse=0.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89: 100%|██████████| 129/129 [00:04<00:00, 31.31it/s, loss=465, v_num=5, train_loss=478.0, val_loss=453.0, val_mse=0.410]\n",
      "Epoch 90:  93%|█████████▎| 120/129 [00:03<00:00, 34.20it/s, loss=485, v_num=5, train_loss=447.0, val_loss=453.0, val_mse=0.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90: 100%|██████████| 129/129 [00:04<00:00, 31.37it/s, loss=467, v_num=5, train_loss=468.0, val_loss=453.0, val_mse=0.409]\n",
      "Epoch 91:  93%|█████████▎| 120/129 [00:03<00:00, 33.20it/s, loss=459, v_num=5, train_loss=465.0, val_loss=453.0, val_mse=0.409] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91: 100%|██████████| 129/129 [00:04<00:00, 30.49it/s, loss=478, v_num=5, train_loss=499.0, val_loss=453.0, val_mse=0.409]\n",
      "Epoch 92:  93%|█████████▎| 120/129 [00:03<00:00, 33.96it/s, loss=468, v_num=5, train_loss=439.0, val_loss=453.0, val_mse=0.409] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92: 100%|██████████| 129/129 [00:04<00:00, 31.23it/s, loss=473, v_num=5, train_loss=487.0, val_loss=453.0, val_mse=0.410]\n",
      "Epoch 93:  93%|█████████▎| 120/129 [00:03<00:00, 34.37it/s, loss=451, v_num=5, train_loss=447.0, val_loss=453.0, val_mse=0.410] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93: 100%|██████████| 129/129 [00:04<00:00, 31.44it/s, loss=451, v_num=5, train_loss=490.0, val_loss=453.0, val_mse=0.409]\n",
      "Epoch 94:  93%|█████████▎| 120/129 [00:03<00:00, 34.19it/s, loss=468, v_num=5, train_loss=428.0, val_loss=453.0, val_mse=0.409] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94: 100%|██████████| 129/129 [00:04<00:00, 31.35it/s, loss=465, v_num=5, train_loss=446.0, val_loss=453.0, val_mse=0.409]\n",
      "Epoch 95:  93%|█████████▎| 120/129 [00:03<00:00, 34.24it/s, loss=452, v_num=5, train_loss=458.0, val_loss=453.0, val_mse=0.409] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95: 100%|██████████| 129/129 [00:04<00:00, 31.28it/s, loss=449, v_num=5, train_loss=431.0, val_loss=453.0, val_mse=0.408]\n",
      "Epoch 96:  93%|█████████▎| 120/129 [00:03<00:00, 34.23it/s, loss=452, v_num=5, train_loss=464.0, val_loss=453.0, val_mse=0.408] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96: 100%|██████████| 129/129 [00:04<00:00, 31.40it/s, loss=461, v_num=5, train_loss=393.0, val_loss=453.0, val_mse=0.408]\n",
      "Epoch 97:  93%|█████████▎| 120/129 [00:03<00:00, 33.54it/s, loss=455, v_num=5, train_loss=462.0, val_loss=453.0, val_mse=0.408] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97: 100%|██████████| 129/129 [00:04<00:00, 30.78it/s, loss=456, v_num=5, train_loss=440.0, val_loss=453.0, val_mse=0.408]\n",
      "Epoch 98:  93%|█████████▎| 120/129 [00:03<00:00, 34.06it/s, loss=481, v_num=5, train_loss=444.0, val_loss=453.0, val_mse=0.408] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98: 100%|██████████| 129/129 [00:04<00:00, 31.24it/s, loss=469, v_num=5, train_loss=470.0, val_loss=453.0, val_mse=0.408]\n",
      "Epoch 99:  93%|█████████▎| 120/129 [00:03<00:00, 33.55it/s, loss=454, v_num=5, train_loss=433.0, val_loss=453.0, val_mse=0.408] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 129/129 [00:04<00:00, 30.73it/s, loss=468, v_num=5, train_loss=524.0, val_loss=453.0, val_mse=0.408]\n",
      "Epoch 99: 100%|██████████| 129/129 [00:04<00:00, 30.52it/s, loss=468, v_num=5, train_loss=524.0, val_loss=453.0, val_mse=0.408]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e44b8-35f7-4d03-81da-0cc8991a4c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_lightning",
   "language": "python",
   "name": "py39_lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
