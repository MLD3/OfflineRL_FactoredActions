{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a68572b-0f34-4282-8ce4-c1fc61762ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EpisodicBufferO(Dataset):\n",
    "    def __init__(self, state_dim, num_actions, horizon, buffer_size=0):\n",
    "        self.max_size = int(buffer_size)\n",
    "        self.horizon = horizon\n",
    "        self.state = torch.zeros((self.max_size, horizon, state_dim))\n",
    "        self.action = torch.zeros((self.max_size, horizon, 1), dtype=torch.long)\n",
    "        self.reward = torch.zeros((self.max_size, horizon, 1))\n",
    "        self.not_done = torch.zeros((self.max_size, horizon, 1))\n",
    "        self.pibs = torch.zeros((self.max_size, horizon, num_actions))\n",
    "        self.estm_pibs = torch.zeros((self.max_size, horizon, num_actions))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.state)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.state[idx],\n",
    "            self.action[idx],\n",
    "            self.reward[idx],\n",
    "            self.not_done[idx],\n",
    "            self.pibs[idx],\n",
    "            self.estm_pibs[idx],\n",
    "        )\n",
    "    \n",
    "    def load(self, filename):\n",
    "        data = torch.load(filename)\n",
    "        self.state = data['statevecs'][:, :-1, :]\n",
    "        self.action = data['actions'][:, 1:].unsqueeze(-1)  # Need to offset by 1 so that we predict actions that have not yet occurred\n",
    "        self.reward = data['rewards'][:, 1:].unsqueeze(-1)  # Need to offset by 1\n",
    "        self.not_done = data['notdones'][:, 1:].unsqueeze(-1)\n",
    "        self.pibs = data['pibs'][:, :-1, :]\n",
    "        self.estm_pibs = data['estm_pibs'][:, :-1, :]\n",
    "        print(f\"Episodic Buffer loaded with {len(self)} episides.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d49518-449a-4453-94e4-c5af1f4f4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 64\n",
    "num_actions = 25\n",
    "horizon = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6631c6c6-70fa-4ef5-b2e9-a7f4fc152ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "def remap_rewards(R, args):\n",
    "    R = np.select([R == 0, R == -1, R == 1], [args.R_immed, args.R_death, args.R_disch,], R)\n",
    "    return torch.tensor(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253fc0a9-f391-4fd9-b04f-563a4273bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodic Buffer loaded with 2894 episides.\n"
     ]
    }
   ],
   "source": [
    "test_episodes_O = EpisodicBufferO(state_dim, num_actions, horizon)\n",
    "test_episodes_O.load('../data/episodes+encoded_state+knn_pibs/test_data.pt')\n",
    "test_episodes_O.reward = remap_rewards(test_episodes_O.reward, SimpleNamespace(**{'R_immed': 0.0, 'R_death': 0.0, 'R_disch': 100.0}))\n",
    "\n",
    "tmp_test_episodes_loader_O = DataLoader(test_episodes_O, batch_size=len(test_episodes_O), shuffle=False)\n",
    "test_batch_O = next(iter(tmp_test_episodes_loader_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ca7b2-226d-43cd-a0dc-32d95362fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get knn highest probability action index, check agreement with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c0d55e-a0eb-40f4-87a0-8c6e1ce892c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, not_dones, pibs, estm_pibs = test_batch_O\n",
    "rewards = rewards[:, :, 0].cpu().numpy()\n",
    "n, horizon, _ = states.shape\n",
    "discounted_rewards = rewards * (1.0 ** np.arange(horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a6f923b-3783-472c-9e81-63c40a125d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2894, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estm_pibs.argmax(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e1ab74-8e92-452c-b46c-ebda63b55d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2894, 20, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6adf1d0-3171-4255-b1e3-2ffc167a9175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7347, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rough estimate\n",
    "(estm_pibs.argmax(dim=2) == actions.squeeze()).to(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "588d167c-b6dd-4d81-9637-531803cea410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5716, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# top 1 knn action\n",
    "cnt_match, cnt_all = 0.0, 0.0\n",
    "for idx in range(n):\n",
    "    lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "    a_obs = actions[idx, :lng, 0]\n",
    "    a_prd = estm_pibs[idx, :lng].argmax(dim=-1)\n",
    "    cnt_all += lng\n",
    "    cnt_match += (a_obs == a_prd).to(float).sum()\n",
    "\n",
    "print(cnt_match/cnt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5707d662-5cca-46ab-97e6-eed7fb181df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7445, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# top 2 knn actions\n",
    "cnt_match, cnt_all = 0.0, 0.0\n",
    "for idx in range(n):\n",
    "    lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "    a_obs = actions[idx, :lng, 0]\n",
    "    a_prd = torch.argsort(estm_pibs[idx, :lng], descending=True, dim=-1)\n",
    "    cnt_all += lng\n",
    "    cnt_match += (a_obs.unsqueeze(1) == a_prd[:, :2]).to(float).sum(dim=1).sum()\n",
    "\n",
    "print(cnt_match/cnt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7908cb3-3299-4d32-b3f5-aaa230dd3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8752, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# top 5 knn actions\n",
    "cnt_match, cnt_all = 0.0, 0.0\n",
    "for idx in range(n):\n",
    "    lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "    a_obs = actions[idx, :lng, 0]\n",
    "    a_prd = torch.argsort(estm_pibs[idx, :lng], descending=True, dim=-1)\n",
    "    cnt_all += lng\n",
    "    cnt_match += (a_obs.unsqueeze(1) == a_prd[:, :5]).to(float).sum(dim=1).sum()\n",
    "\n",
    "print(cnt_match/cnt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c663d4b4-47fe-40db-aa66-dab0061be7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9349, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# top 10 knn actions\n",
    "cnt_match, cnt_all = 0.0, 0.0\n",
    "for idx in range(n):\n",
    "    lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "    a_obs = actions[idx, :lng, 0]\n",
    "    a_prd = torch.argsort(estm_pibs[idx, :lng], descending=True, dim=-1)\n",
    "    cnt_all += lng\n",
    "    cnt_match += (a_obs.unsqueeze(1) == a_prd[:, :10]).to(float).sum(dim=1).sum()\n",
    "\n",
    "print(cnt_match/cnt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba6ce4b7-0b8c-4502-a98b-7a0a38bfd373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5783, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "cnt_match, cnt_all = 0.0, 0.0\n",
    "for idx in range(n):\n",
    "    lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "    a_obs = actions[idx, :lng, 0]\n",
    "    a_prd = pibs[idx, :lng].argmax(dim=-1)\n",
    "    cnt_all += lng\n",
    "    cnt_match += (a_obs == a_prd).to(float).sum()\n",
    "\n",
    "print(cnt_match/cnt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645bee1-9e25-44c1-b43b-f6e8f54f8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reference of WIS loop\n",
    "# for idx in range(n):\n",
    "#     lng = (not_dones[idx, :, 0].sum() + 1).item()  # all but the final transition has notdone==1\n",
    "\n",
    "#     # Predict Q-values and Imitation probabilities\n",
    "#     q, _, i = self.Q(states[idx])\n",
    "#     imt = F.log_softmax(i.reshape(-1, 2, 5), dim=-1).exp()\n",
    "#     imt = (imt / imt.max(axis=-1, keepdim=True).values > self.threshold).float()\n",
    "\n",
    "#     # Factored action remapping\n",
    "#     q = q @ self.all_subactions_vec.T\n",
    "#     imt = torch.einsum('bi,bj->bji', (imt[:,0,:], imt[:,1,:])).reshape(-1, 25)\n",
    "\n",
    "#     # Use large negative number to mask actions from argmax\n",
    "#     a_id = (imt * q + (1. - imt) * torch.finfo().min).argmax(axis=1).cpu().numpy()\n",
    "#     pie_soft = np.zeros((horizon, 25))\n",
    "#     pie_soft += eps * estm_pibs[idx].cpu().numpy() # Soften using training behavior policy\n",
    "#     pie_soft[range(horizon), a_id] += (1.0 - eps)\n",
    "\n",
    "#     # Compute importance sampling ratios\n",
    "#     a_obs = actions[idx, :, 0]\n",
    "#     ir[idx, :lng] = pie_soft[range(lng), a_obs[:lng].cpu().numpy()] / pibs[idx, range(lng), a_obs[:lng]].cpu().numpy()\n",
    "#     ir[idx, lng:] = 1  # Mask out the padded timesteps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_lightning",
   "language": "python",
   "name": "py39_lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
